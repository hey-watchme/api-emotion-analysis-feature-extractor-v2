#!/usr/bin/env python3
"""
KushinadaéŸ³å£°æ„Ÿæƒ…èªè­˜API - OpenSMILEäº’æ›ç‰ˆ
æ—¥æœ¬èªéŸ³å£°ã®æ„Ÿæƒ…èªè­˜ã‚’è¡Œã†APIã‚µãƒ¼ãƒ“ã‚¹
ç”£ç·ç ”ã®Kushinadaãƒ¢ãƒ‡ãƒ«ï¼ˆHuBERT-largeï¼‰ã‚’ä½¿ç”¨
"""

import os
import gc
import time
import tempfile
import torch
import librosa
import numpy as np
import warnings
from transformers import HubertModel
import boto3
from botocore.exceptions import ClientError
from dotenv import load_dotenv
from supabase import create_client, Client

from fastapi import FastAPI, HTTPException, status
from fastapi.responses import JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn
from typing import Dict, List, Optional

from models import (
    HealthResponse,
    ErrorResponse,
    EmotionFeaturesRequest,
    EmotionFeaturesResponse,
    ChunkResult,
    EmotionScore
)
from supabase_service import SupabaseService

warnings.filterwarnings('ignore')

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

# FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®åˆæœŸåŒ–
app = FastAPI(
    title="Kushinada Emotion Recognition API - OpenSMILE Compatible",
    description="Kushinadaãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸfile_pathsãƒ™ãƒ¼ã‚¹ã®æ„Ÿæƒ…åˆ†æã‚µãƒ¼ãƒ“ã‚¹",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORSãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢ã®è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Supabaseã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
supabase_url = os.getenv("SUPABASE_URL")
supabase_key = os.getenv("SUPABASE_KEY")
if supabase_url and supabase_key:
    supabase_client: Client = create_client(supabase_url, supabase_key)
    supabase_service = SupabaseService(supabase_client)
    print(f"âœ… Supabaseæ¥ç¶šè¨­å®šå®Œäº†: {supabase_url}")
else:
    supabase_service = None
    print("âš ï¸ Supabaseç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

# AWS S3ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
aws_access_key_id = os.getenv('AWS_ACCESS_KEY_ID')
aws_secret_access_key = os.getenv('AWS_SECRET_ACCESS_KEY')
s3_bucket_name = os.getenv('S3_BUCKET_NAME', 'watchme-vault')
aws_region = os.getenv('AWS_REGION', 'us-east-1')

if not aws_access_key_id or not aws_secret_access_key:
    raise ValueError("AWS_ACCESS_KEY_IDãŠã‚ˆã³AWS_SECRET_ACCESS_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

s3_client = boto3.client(
    's3',
    aws_access_key_id=aws_access_key_id,
    aws_secret_access_key=aws_secret_access_key,
    region_name=aws_region
)
print(f"âœ… AWS S3æ¥ç¶šè¨­å®šå®Œäº†: ãƒã‚±ãƒƒãƒˆ={s3_bucket_name}, ãƒªãƒ¼ã‚¸ãƒ§ãƒ³={aws_region}")

# ã‚»ã‚°ãƒ¡ãƒ³ãƒˆè¨­å®š
SEGMENT_DURATION = 10.0  # 10ç§’å›ºå®šï¼ˆæœ€é©ãƒãƒ©ãƒ³ã‚¹ç¢ºèªæ¸ˆã¿ï¼‰

# Kushinadaæ„Ÿæƒ…ãƒ©ãƒ™ãƒ«ã®è©³ç´°æƒ…å ±ï¼ˆ4æ„Ÿæƒ…ï¼‰
LABELS_INFO = {
    "neutral": {"ja": "ä¸­ç«‹", "en": "Neutral", "group": "neutral"},
    "joy": {"ja": "å–œã³", "en": "Joy", "group": "positive_active"},
    "anger": {"ja": "æ€’ã‚Š", "en": "Anger", "group": "negative_active"},
    "sadness": {"ja": "æ‚²ã—ã¿", "en": "Sadness", "group": "negative_passive"}
}

LABEL_MAP = {
    0: "neutral",
    1: "joy",
    2: "anger",
    3: "sadness"
}


class KushinadaAnalyzer:
    """Kushinadaãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ãŸæ„Ÿæƒ…åˆ†æã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.upstream = None
        self.featurizer_weights = None
        self.projector = None
        self.post_net = None
        self.loaded = False

    def load_models(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰"""
        if self.loaded:
            return

        print("ğŸ”§ Kushinadaãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­...")

        # HuggingFaceãƒˆãƒ¼ã‚¯ãƒ³ã®è¨­å®š
        hf_token = os.getenv('HF_TOKEN')
        if hf_token:
            os.environ['HUGGING_FACE_HUB_TOKEN'] = hf_token

        # HuBERT ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
        self.upstream = HubertModel.from_pretrained("imprt/kushinada-hubert-large")
        self.upstream.eval()

        # ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰ï¼ˆHugging Faceã‹ã‚‰è‡ªå‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
        from huggingface_hub import hf_hub_download

        checkpoint_path = hf_hub_download(
            repo_id="imprt/kushinada-hubert-large-jtes-er",
            filename="s3prl/result/downstream/kushinada-hubert-large-jtes-er_fold1/dev-best.ckpt",
            token=os.getenv("HF_TOKEN")
        )

        print(f"âœ… ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰: {checkpoint_path}")

        downstream_ckpt = torch.load(checkpoint_path, map_location='cpu', weights_only=False)

        # Featurizer weightsï¼ˆå…¨25å±¤ã®é‡ã¿ï¼‰
        if 'Featurizer' in downstream_ckpt:
            self.featurizer_weights = downstream_ckpt['Featurizer']['weights']

        downstream_dict = downstream_ckpt["Downstream"]

        # Projectorï¼ˆ1024æ¬¡å…ƒ â†’ 256æ¬¡å…ƒï¼‰
        projector_weight = downstream_dict["projector.weight"]
        self.projector = torch.nn.Linear(projector_weight.size(1), projector_weight.size(0))
        self.projector.load_state_dict({
            "weight": projector_weight,
            "bias": downstream_dict["projector.bias"]
        })
        self.projector.eval()

        # Post-netï¼ˆClassifier: 256æ¬¡å…ƒ â†’ 4æ¬¡å…ƒï¼‰
        post_net_weight = downstream_dict["model.post_net.linear.weight"]
        self.post_net = torch.nn.Linear(post_net_weight.size(1), post_net_weight.size(0))
        self.post_net.load_state_dict({
            "weight": post_net_weight,
            "bias": downstream_dict["model.post_net.linear.bias"]
        })
        self.post_net.eval()

        self.loaded = True
        print("âœ… Kushinadaãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†ï¼\n")

    def weighted_sum_layers(self, all_hidden_states):
        """å…¨25å±¤ã®é‡ã¿ä»˜ãå’Œã‚’è¨ˆç®—ï¼ˆFeaturizerï¼‰"""
        norm_weights = torch.softmax(self.featurizer_weights, dim=0)
        stacked = torch.stack(all_hidden_states, dim=0)
        weighted = (stacked * norm_weights.view(-1, 1, 1, 1)).sum(dim=0)
        return weighted

    def predict_segment(self, waveform_segment):
        """
        å˜ä¸€ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ„Ÿæƒ…åˆ†æ

        Args:
            waveform_segment: torch.Tensor [samples]

        Returns:
            dict: æ„Ÿæƒ…åˆ†æçµæœ
        """
        if len(waveform_segment) < 1600:  # 0.1ç§’æœªæº€ã¯å‡¦ç†ã—ãªã„
            return None

        waveform = waveform_segment.unsqueeze(0)  # [1, samples]

        with torch.no_grad():
            # HuBERT: å…¨25å±¤ã‚’å–å¾—
            outputs = self.upstream(waveform, output_hidden_states=True)
            all_hidden_states = outputs.hidden_states

            # Featurizer: å…¨å±¤ã®é‡ã¿ä»˜ãå’Œ
            if self.featurizer_weights is not None:
                features = self.weighted_sum_layers(all_hidden_states)
            else:
                features = outputs.last_hidden_state

            # MeanPooling
            pooled = features.mean(dim=1)

            # Projector â†’ Classifier
            projected = self.projector(pooled)
            logits = self.post_net(projected)
            probs = torch.softmax(logits, dim=-1)

        probs_np = probs[0].numpy()
        predicted_class = probs_np.argmax()

        # 4æ„Ÿæƒ…ã™ã¹ã¦ã®ã‚¹ã‚³ã‚¢ã‚’å–å¾—
        emotion_scores = {LABEL_MAP[i]: float(probs_np[i]) for i in range(4)}
        dominant_emotion = LABEL_MAP[predicted_class]
        confidence = float(probs_np[predicted_class])

        return {
            "dominant_emotion": dominant_emotion,
            "confidence": confidence,
            "all_emotions": emotion_scores
        }

    def analyze_audio_file(self, audio_path: str) -> tuple:
        """
        éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’10ç§’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã—ã¦æ„Ÿæƒ…åˆ†æ

        Args:
            audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            tuple: (ã‚»ã‚°ãƒ¡ãƒ³ãƒˆçµæœãƒªã‚¹ãƒˆ, ç·æ™‚é–“)
        """
        if not self.loaded:
            self.load_models()

        # éŸ³å£°èª­ã¿è¾¼ã¿ï¼ˆ16kHzã€ãƒ¢ãƒãƒ©ãƒ«ï¼‰
        waveform_np, sample_rate = librosa.load(audio_path, sr=16000, mono=True)
        total_duration = len(waveform_np) / 16000

        # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²
        segment_samples = int(SEGMENT_DURATION * 16000)
        num_segments = int(np.ceil(len(waveform_np) / segment_samples))

        chunks_results = []

        for i in range(num_segments):
            chunk_id = i + 1
            start_sample = i * segment_samples
            end_sample = min((i + 1) * segment_samples, len(waveform_np))

            start_time = start_sample / 16000
            end_time = end_sample / 16000
            duration = end_time - start_time

            # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã‚’æŠ½å‡º
            segment_waveform = torch.from_numpy(waveform_np[start_sample:end_sample]).float()

            # æ„Ÿæƒ…åˆ†æå®Ÿè¡Œ
            result = self.predict_segment(segment_waveform)

            if result:
                # 4æ„Ÿæƒ…ã™ã¹ã¦ã‚’emotionsé…åˆ—ã«æ•´å½¢
                emotions = []
                for label_id in range(4):
                    label = LABEL_MAP[label_id]
                    score = result["all_emotions"][label]
                    info = LABELS_INFO[label]

                    emotions.append({
                        "label": label,
                        "score": round(score, 6),
                        "percentage": round(score * 100, 3),
                        "name_ja": info["ja"],
                        "name_en": info["en"],
                        "group": info["group"]
                    })

                # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
                emotions.sort(key=lambda x: x["score"], reverse=True)

                # ãƒãƒ£ãƒ³ã‚¯çµæœã‚’ä½œæˆ
                chunk_result = {
                    "chunk_id": chunk_id,
                    "start_time": round(start_time, 1),
                    "end_time": round(end_time, 1),
                    "duration": round(duration, 1),
                    "emotions": emotions,
                    "primary_emotion": emotions[0] if emotions else None
                }

                chunks_results.append(chunk_result)

            # ãƒ¡ãƒ¢ãƒªè§£æ”¾
            del segment_waveform
            gc.collect()

        # ãƒ¡ãƒ¢ãƒªè§£æ”¾
        del waveform_np
        gc.collect()

        return chunks_results, int(total_duration)


# ã‚°ãƒ­ãƒ¼ãƒãƒ«å¤‰æ•°ã§ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼ã‚’ä¿æŒ
kushinada_analyzer = None


def extract_info_from_file_path(file_path: str) -> dict:
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±ã‚’æŠ½å‡º

    Args:
        file_path: 'files/device_id/date/time/audio.wav' å½¢å¼

    Returns:
        dict: {'device_id': str, 'date': str, 'time_block': str}
    """
    parts = file_path.split('/')
    if len(parts) >= 5:
        return {
            'device_id': parts[1],
            'date': parts[2],
            'time_block': parts[3]
        }
    else:
        raise ValueError(f"ä¸æ­£ãªãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹å½¢å¼: {file_path}")


async def update_audio_files_status(file_path: str) -> bool:
    """audio_filesãƒ†ãƒ¼ãƒ–ãƒ«ã®emotion_features_statusã‚’æ›´æ–°

    Args:
        file_path: å‡¦ç†å®Œäº†ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        bool: æ›´æ–°æˆåŠŸå¯å¦
    """
    try:
        update_response = supabase_client.table('audio_files') \
            .update({'emotion_features_status': 'completed'}) \
            .eq('file_path', file_path) \
            .execute()

        if update_response.data:
            print(f"âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°æˆåŠŸ: {file_path}")
            return True
        else:
            print(f"âš ï¸ å¯¾è±¡ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            return False

    except Exception as e:
        print(f"âŒ ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ›´æ–°ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


# èµ·å‹•æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
@app.on_event("startup")
async def startup_event():
    global kushinada_analyzer
    kushinada_analyzer = KushinadaAnalyzer()
    kushinada_analyzer.load_models()


@app.get("/", response_model=dict)
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "Kushinada Emotion Recognition API - OpenSMILE Compatible",
        "version": "2.0.0",
        "model": "kushinada-hubert-large-jtes-er",
        "segment_duration": f"{SEGMENT_DURATION}ç§’",
        "emotions": list(LABELS_INFO.keys()),
        "docs": "/docs",
        "health": "/health"
    }


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        return HealthResponse(
            status="healthy",
            service="Kushinada API - OpenSMILE Compatible",
            version="2.0.0",
            model_loaded=kushinada_analyzer is not None and kushinada_analyzer.loaded
        )
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail=f"Service unhealthy: {str(e)}"
        )


@app.post("/process/emotion-features", response_model=EmotionFeaturesResponse)
async def process_emotion_features(request: EmotionFeaturesRequest):
    """file_pathsãƒ™ãƒ¼ã‚¹ã®æ„Ÿæƒ…åˆ†æï¼ˆOpenSMILEäº’æ›ï¼‰"""
    start_time = time.time()

    try:
        print(f"\n=== Kushinada file_pathsãƒ™ãƒ¼ã‚¹ã«ã‚ˆã‚‹æ„Ÿæƒ…åˆ†æé–‹å§‹ ===")
        print(f"file_pathsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿: {len(request.file_paths)}ä»¶ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
        print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·: {SEGMENT_DURATION}ç§’")
        print(f"=" * 50)

        if not supabase_service:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Supabaseã‚µãƒ¼ãƒ“ã‚¹ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ç’°å¢ƒå¤‰æ•°ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
            )

        if not kushinada_analyzer or not kushinada_analyzer.loaded:
            raise HTTPException(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                detail="Kushinadaãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"
            )

        processed_files = 0
        error_files = []
        supabase_records = []

        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆã—ã¦WAVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
        with tempfile.TemporaryDirectory() as temp_dir:
            for file_path in request.file_paths:
                try:
                    print(f"\nğŸ“¥ S3ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«å–å¾—é–‹å§‹: {file_path}")

                    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
                    path_info = extract_info_from_file_path(file_path)
                    device_id = path_info['device_id']
                    date = path_info['date']
                    time_block = path_info['time_block']

                    # S3ã‹ã‚‰ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                    temp_file_path = os.path.join(temp_dir, f"{time_block}.wav")

                    try:
                        s3_client.download_file(s3_bucket_name, file_path, temp_file_path)
                        print(f"âœ… S3ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æˆåŠŸ: {file_path}")
                    except ClientError as e:
                        error_code = e.response['Error']['Code']
                        if error_code == 'NoSuchKey':
                            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
                            error_files.append(file_path)
                            continue
                        else:
                            raise e

                    print(f"ğŸµ Kushinadaæ„Ÿæƒ…åˆ†æé–‹å§‹: {file_path}")

                    # æ„Ÿæƒ…åˆ†æã‚’å®Ÿè¡Œ
                    analysis_start = time.time()
                    chunks_results, duration_seconds = kushinada_analyzer.analyze_audio_file(temp_file_path)
                    processing_time = time.time() - analysis_start

                    processed_files += 1

                    # Supabaseç”¨ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æº–å‚™
                    supabase_record = {
                        "device_id": device_id,
                        "date": date,
                        "time_block": time_block,
                        "filename": os.path.basename(file_path),
                        "duration_seconds": duration_seconds,
                        "features_timeline": chunks_results,  # Kushinadaã®4æ„Ÿæƒ…çµæœ
                        "selected_features_timeline": [],  # ç©ºé…åˆ—ã‚’è¨­å®š
                        "processing_time": processing_time,
                        "error": None
                    }
                    supabase_records.append(supabase_record)

                    # audio_filesãƒ†ãƒ¼ãƒ–ãƒ«ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’æ›´æ–°
                    await update_audio_files_status(file_path)

                    # ä¸»è¦æ„Ÿæƒ…ã‚’è¡¨ç¤º
                    if chunks_results:
                        for chunk in chunks_results:
                            primary = chunk["primary_emotion"]
                            print(f"  ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ{chunk['chunk_id']}: {primary['name_ja']} ({primary['percentage']:.1f}%)")

                    print(f"âœ… å®Œäº†: {file_path} â†’ {len(chunks_results)}ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã®æ„Ÿæƒ…åˆ†æå®Œäº†")

                except Exception as e:
                    error_files.append(file_path)
                    print(f"âŒ ã‚¨ãƒ©ãƒ¼: {file_path} - {str(e)}")

                    # ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚‚Supabaseã«ä¿å­˜
                    try:
                        path_info = extract_info_from_file_path(file_path)
                        supabase_record = {
                            "device_id": path_info['device_id'],
                            "date": path_info['date'],
                            "time_block": path_info['time_block'],
                            "filename": os.path.basename(file_path),
                            "duration_seconds": 0,
                            "features_timeline": [],
                            "selected_features_timeline": [],
                            "processing_time": 0,
                            "error": str(e)
                        }
                        supabase_records.append(supabase_record)
                    except:
                        pass

        # Supabaseã«ãƒãƒƒãƒã§ä¿å­˜
        print(f"\n=== Supabaseä¿å­˜é–‹å§‹ ===")
        print(f"ä¿å­˜å¯¾è±¡: {len(supabase_records)} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        print(f"=" * 50)

        saved_count = 0
        save_errors = []

        if supabase_records:
            try:
                # ãƒãƒƒãƒã§UPSERTå®Ÿè¡Œ
                await supabase_service.batch_upsert_emotion_data(supabase_records)
                saved_count = len(supabase_records)
                print(f"âœ… Supabaseä¿å­˜æˆåŠŸ: {saved_count} ãƒ¬ã‚³ãƒ¼ãƒ‰")
            except Exception as e:
                print(f"âŒ Supabaseãƒãƒƒãƒä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
                # å€‹åˆ¥ã«ä¿å­˜ã‚’è©¦ã¿ã‚‹
                for record in supabase_records:
                    try:
                        await supabase_service.upsert_emotion_data(
                            device_id=record["device_id"],
                            date=record["date"],
                            time_block=record["time_block"],
                            filename=record["filename"],
                            duration_seconds=record["duration_seconds"],
                            features_timeline=record["features_timeline"],
                            processing_time=record["processing_time"],
                            error=record.get("error"),
                            selected_features_timeline=record.get("selected_features_timeline", [])
                        )
                        saved_count += 1
                    except Exception as individual_error:
                        save_errors.append(f"{record['time_block']}: {str(individual_error)}")
                        print(f"âŒ å€‹åˆ¥ä¿å­˜ã‚¨ãƒ©ãƒ¼: {record['time_block']} - {str(individual_error)}")

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ
        total_time = time.time() - start_time

        print(f"\n=== Kushinadaæ„Ÿæƒ…åˆ†æå®Œäº† ===")
        print(f"ğŸ“¥ S3å‡¦ç†: {processed_files} ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"ğŸ’¾ Supabaseä¿å­˜: {saved_count} ãƒ¬ã‚³ãƒ¼ãƒ‰")
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {len(error_files)} ãƒ•ã‚¡ã‚¤ãƒ«")
        print(f"â±ï¸ ç·å‡¦ç†æ™‚é–“: {total_time:.2f}ç§’")
        print(f"=" * 50)

        return EmotionFeaturesResponse(
            success=True,
            processed_files=processed_files,
            saved_count=saved_count,
            error_files=error_files,
            total_processing_time=total_time,
            message=f"S3ã‹ã‚‰{processed_files}å€‹ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã€{saved_count}å€‹ã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’Supabaseã«ä¿å­˜ã—ã¾ã—ãŸ"
        )

    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"æ„Ÿæƒ…åˆ†æå‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        )


@app.exception_handler(Exception)
async def global_exception_handler(request, exc):
    """ã‚°ãƒ­ãƒ¼ãƒãƒ«ä¾‹å¤–ãƒãƒ³ãƒ‰ãƒ©ãƒ¼"""
    return JSONResponse(
        status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
        content=ErrorResponse(
            error="Internal server error",
            detail=str(exc)
        ).dict()
    )


if __name__ == "__main__":
    # ãƒãƒ¼ãƒˆ8018ã§èµ·å‹•ï¼ˆv3ã¨åŒã˜ãƒãƒ¼ãƒˆï¼‰
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8018,
        reload=True,
        log_level="info"
    )
